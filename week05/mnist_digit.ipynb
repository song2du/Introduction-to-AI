{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "83331f2c-8d19-4b13-bd91-e0f9817196b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD,Adam\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edb110b4-4b11-45a2-af3e-67ec3cf9c7f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21a27b98ce0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#데이터 확인\n",
    "digits = datasets.load_digits()\n",
    "plt.imshow(digits.images[0], cmap=plt.cm.gray_r, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f69f10f2-8770-400f-8860-3e54b66f48d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "        [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "        [ 0.,  0., 10., ..., 12.,  1.,  0.]]),\n",
       " 'target': array([0, 1, 2, ..., 8, 9, 8]),\n",
       " 'frame': None,\n",
       " 'feature_names': ['pixel_0_0',\n",
       "  'pixel_0_1',\n",
       "  'pixel_0_2',\n",
       "  'pixel_0_3',\n",
       "  'pixel_0_4',\n",
       "  'pixel_0_5',\n",
       "  'pixel_0_6',\n",
       "  'pixel_0_7',\n",
       "  'pixel_1_0',\n",
       "  'pixel_1_1',\n",
       "  'pixel_1_2',\n",
       "  'pixel_1_3',\n",
       "  'pixel_1_4',\n",
       "  'pixel_1_5',\n",
       "  'pixel_1_6',\n",
       "  'pixel_1_7',\n",
       "  'pixel_2_0',\n",
       "  'pixel_2_1',\n",
       "  'pixel_2_2',\n",
       "  'pixel_2_3',\n",
       "  'pixel_2_4',\n",
       "  'pixel_2_5',\n",
       "  'pixel_2_6',\n",
       "  'pixel_2_7',\n",
       "  'pixel_3_0',\n",
       "  'pixel_3_1',\n",
       "  'pixel_3_2',\n",
       "  'pixel_3_3',\n",
       "  'pixel_3_4',\n",
       "  'pixel_3_5',\n",
       "  'pixel_3_6',\n",
       "  'pixel_3_7',\n",
       "  'pixel_4_0',\n",
       "  'pixel_4_1',\n",
       "  'pixel_4_2',\n",
       "  'pixel_4_3',\n",
       "  'pixel_4_4',\n",
       "  'pixel_4_5',\n",
       "  'pixel_4_6',\n",
       "  'pixel_4_7',\n",
       "  'pixel_5_0',\n",
       "  'pixel_5_1',\n",
       "  'pixel_5_2',\n",
       "  'pixel_5_3',\n",
       "  'pixel_5_4',\n",
       "  'pixel_5_5',\n",
       "  'pixel_5_6',\n",
       "  'pixel_5_7',\n",
       "  'pixel_6_0',\n",
       "  'pixel_6_1',\n",
       "  'pixel_6_2',\n",
       "  'pixel_6_3',\n",
       "  'pixel_6_4',\n",
       "  'pixel_6_5',\n",
       "  'pixel_6_6',\n",
       "  'pixel_6_7',\n",
       "  'pixel_7_0',\n",
       "  'pixel_7_1',\n",
       "  'pixel_7_2',\n",
       "  'pixel_7_3',\n",
       "  'pixel_7_4',\n",
       "  'pixel_7_5',\n",
       "  'pixel_7_6',\n",
       "  'pixel_7_7'],\n",
       " 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
       "         [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
       "         [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
       "         [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
       "         [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
       "         [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
       "         [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
       "         [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
       "         [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]),\n",
       " 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n:Number of Instances: 1797\\n:Number of Attributes: 64\\n:Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n:Missing Attribute Values: None\\n:Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n:Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. dropdown:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\\n\"}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bf923c6b-a04d-4c70-8b80-51a32ccfa39e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#데이터 평탄화\n",
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a005271b-b7e5-45eb-aafc-efb8272b1cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#훈련, 테스트 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, digits.target, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd5c1dad-f4d3-46ee-bdf4-fd77da87b876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1437, 64), (360, 64), (1437,), (360,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517d1cad-8d95-42fe-a1c4-c6feb3c1c23b",
   "metadata": {},
   "source": [
    "# 머신러닝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d24cb75-ac69-41e3-a189-f4cac65c5dfc",
   "metadata": {},
   "source": [
    "### RF(랜덤 포레스트) 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e1e4238-c8cc-4dd7-84c2-fb190bee37d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.975\n",
      "confusion matrix:\n",
      "[[37  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 27  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 42  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 43  0  0  0  0  1  0]\n",
      " [ 0  0  0  0 32  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 33  0  0  0  0]\n",
      " [ 0  0  0  0  0  1 41  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 37  0  0]\n",
      " [ 0  0  1  1  0  1  0  0 26  0]\n",
      " [ 0  0  0  1  0  0  0  1  2 33]]\n"
     ]
    }
   ],
   "source": [
    "# 모델 선언\n",
    "rf_clf = RandomForestClassifier(random_state=0)\n",
    "# 모델 학습\n",
    "rf_clf.fit(X_train, y_train)\n",
    "#예측 생성\n",
    "pred_rf = rf_clf.predict(X_test)\n",
    "# accuracy 및 confusion matrix 확인\n",
    "acc_rf = accuracy_score(y_test, pred_rf)\n",
    "print(f\"accuracy: {acc_rf}\")\n",
    "cm_rf = confusion_matrix(y_test, pred_rf)\n",
    "print(f\"confusion matrix:\\n{cm_rf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4402730-90a4-4dad-a80d-4d588f910acf",
   "metadata": {},
   "source": [
    "### LR(로지스틱 회귀) 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "deea7a37-f15d-4856-a48d-ed4ec658f3ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9666666666666667\n",
      "confusion matrix:\n",
      "[[37  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 27  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 42  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 43  0  0  0  0  1  0]\n",
      " [ 0  0  0  0 32  0  0  0  0  0]\n",
      " [ 0  1  0  0  0 32  0  0  0  0]\n",
      " [ 0  0  0  0  0  1 41  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 36  0  1]\n",
      " [ 0  2  0  0  0  0  0  0 27  0]\n",
      " [ 1  0  0  2  0  0  0  0  3 31]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# 모델 선언\n",
    "lr_clf = LogisticRegression(random_state=0)\n",
    "# 모델 학습\n",
    "lr_clf.fit(X_train, y_train)\n",
    "#예측 생성\n",
    "pred_lr = lr_clf.predict(X_test)\n",
    "# accuracy 및 confusion matrix 확인\n",
    "acc_lr = accuracy_score(y_test, pred_lr)\n",
    "print(f\"accuracy: {acc_lr}\")\n",
    "cm_lr = confusion_matrix(y_test, pred_lr)\n",
    "print(f\"confusion matrix:\\n{cm_lr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308dfa08-c2cb-4cda-933c-01503659806c",
   "metadata": {},
   "source": [
    "### KNN(K 최근접 이웃) 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70ea1bf8-3e60-4df0-a5e0-bc44b4887b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9861111111111112\n",
      "confusion matrix:\n",
      "[[37  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 27  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 42  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 44  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 32  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 32  0  0  0  1]\n",
      " [ 0  0  0  0  0  0 42  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 37  0  0]\n",
      " [ 0  1  0  1  0  0  0  0 27  0]\n",
      " [ 0  0  0  0  1  0  0  0  1 35]]\n"
     ]
    }
   ],
   "source": [
    "#모델 선언\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=3)\n",
    "# 모델 학습\n",
    "knn_clf.fit(X_train, y_train)\n",
    "#예측 생성\n",
    "pred_knn = knn_clf.predict(X_test)\n",
    "# accuracy 및 confusion matrix 확인\n",
    "acc_knn = accuracy_score(y_test, pred_knn)\n",
    "print(f\"accuracy: {acc_knn}\")\n",
    "cm_knn = confusion_matrix(y_test, pred_knn)\n",
    "print(f\"confusion matrix:\\n{cm_knn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e46de8-1455-458e-a3f7-7ec821e556ed",
   "metadata": {},
   "source": [
    "### SVM(서포트 벡터 머신) 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "352f5ec4-c27e-4bcd-8709-13504ec681c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9888888888888889\n",
      "confusion matrix:\n",
      "[[37  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 27  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 42  0  0  0  0  0  0  0]\n",
      " [ 0  0  1 43  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 32  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 33  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 42  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 36  0  1]\n",
      " [ 0  1  0  0  0  0  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0  1  0 36]]\n"
     ]
    }
   ],
   "source": [
    "# 모델 선언\n",
    "svm_clf = SVC(random_state=0)\n",
    "# 모델 학습\n",
    "svm_clf.fit(X_train, y_train)\n",
    "#예측 생성\n",
    "pred_svm = svm_clf.predict(X_test)\n",
    "# accuracy 및 confusion matrix 확인\n",
    "acc_svm = accuracy_score(y_test, pred_svm)\n",
    "print(f\"accuracy: {acc_svm}\")\n",
    "cm_svm = confusion_matrix(y_test, pred_svm)\n",
    "print(f\"confusion matrix:\\n{cm_svm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88605a7-4547-49ec-9c58-69f7bb2f375d",
   "metadata": {},
   "source": [
    "# 딥러닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c872a5f-6148-4efa-92ba-f788d004ab32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 인코딩\n",
    "y_1hot = pd.get_dummies(digits.target).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "99902f17-41e0-4cbd-8752-de302d64f20f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False, False, False, False, False, False, False, False,\n",
       "        False],\n",
       "       [False,  True, False, False, False, False, False, False, False,\n",
       "        False],\n",
       "       [False, False,  True, False, False, False, False, False, False,\n",
       "        False],\n",
       "       [False, False, False,  True, False, False, False, False, False,\n",
       "        False],\n",
       "       [False, False, False, False,  True, False, False, False, False,\n",
       "        False]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_1hot[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8b6f286b-0cd9-4d04-b251-d157b5f8a71e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1437, 64), (360, 64), (1437, 10), (360, 10))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#테스트, 트레인 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, y_1hot, test_size=0.2)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "712dec41-b3bd-4d95-b97b-8d14be929342",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\송이두\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,300</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">630</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">930</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">930</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">310</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │           \u001b[38;5;34m1,300\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)                  │             \u001b[38;5;34m630\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)                  │             \u001b[38;5;34m930\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)                  │             \u001b[38;5;34m930\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m310\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,100</span> (16.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,100\u001b[0m (16.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,100</span> (16.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,100\u001b[0m (16.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(20,input_shape=(64,),activation='relu'))\n",
    "model.add(Dense(30,activation='relu'))\n",
    "model.add(Dense(30,activation='relu'))\n",
    "model.add(Dense(30,activation='relu'))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "58dbb624-3f80-4c2c-8273-c7388322fe47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0071 - val_accuracy: 0.9653 - val_loss: 0.1381\n",
      "Epoch 2/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0083 - val_accuracy: 0.9688 - val_loss: 0.1366\n",
      "Epoch 3/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 0.9688 - val_loss: 0.1495\n",
      "Epoch 4/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.9514 - val_loss: 0.1483\n",
      "Epoch 5/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 0.9688 - val_loss: 0.1447\n",
      "Epoch 6/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.9688 - val_loss: 0.1378\n",
      "Epoch 7/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.9688 - val_loss: 0.1410\n",
      "Epoch 8/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.9653 - val_loss: 0.1411\n",
      "Epoch 9/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.9653 - val_loss: 0.1430\n",
      "Epoch 10/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.9653 - val_loss: 0.1409\n",
      "Epoch 11/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.9549 - val_loss: 0.1425\n",
      "Epoch 12/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9688 - val_loss: 0.1423\n",
      "Epoch 13/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9583 - val_loss: 0.1455\n",
      "Epoch 14/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9688 - val_loss: 0.1419\n",
      "Epoch 15/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9722 - val_loss: 0.1426\n",
      "Epoch 16/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9618 - val_loss: 0.1415\n",
      "Epoch 17/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9653 - val_loss: 0.1471\n",
      "Epoch 18/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9688 - val_loss: 0.1480\n",
      "Epoch 19/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9618 - val_loss: 0.1454\n",
      "Epoch 20/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9722 - val_loss: 0.1482\n",
      "Epoch 21/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9722 - val_loss: 0.1466\n",
      "Epoch 22/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9722 - val_loss: 0.1490\n",
      "Epoch 23/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9688 - val_loss: 0.1493\n",
      "Epoch 24/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9653 - val_loss: 0.1470\n",
      "Epoch 25/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9688 - val_loss: 0.1474\n",
      "Epoch 26/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 9.9948e-04 - val_accuracy: 0.9653 - val_loss: 0.1487\n",
      "Epoch 27/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 9.3307e-04 - val_accuracy: 0.9688 - val_loss: 0.1485\n",
      "Epoch 28/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 8.8872e-04 - val_accuracy: 0.9653 - val_loss: 0.1490\n",
      "Epoch 29/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 8.6178e-04 - val_accuracy: 0.9688 - val_loss: 0.1501\n",
      "Epoch 30/30\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 9.0733e-04 - val_accuracy: 0.9688 - val_loss: 0.1537\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n"
     ]
    }
   ],
   "source": [
    "model_history=model.fit(x=X_train, y=y_train, epochs=30, batch_size=30,validation_split=0.2)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "697755cb-d05b-4e4c-9788-30b9567d7a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97        47\n",
      "           1       0.98      0.95      0.96        43\n",
      "           2       0.97      0.89      0.93        37\n",
      "           3       0.91      0.97      0.94        33\n",
      "           4       1.00      0.97      0.98        31\n",
      "           5       0.92      1.00      0.96        35\n",
      "           6       0.97      0.97      0.97        32\n",
      "           7       0.93      0.97      0.95        39\n",
      "           8       0.94      0.94      0.94        35\n",
      "           9       0.96      0.93      0.95        28\n",
      "\n",
      "    accuracy                           0.96       360\n",
      "   macro avg       0.96      0.96      0.96       360\n",
      "weighted avg       0.96      0.96      0.96       360\n",
      "\n",
      "[[45  0  0  0  0  1  0  0  0  1]\n",
      " [ 0 41  0  0  0  1  1  0  0  0]\n",
      " [ 0  1 33  1  0  0  0  1  1  0]\n",
      " [ 0  0  0 32  0  0  0  1  0  0]\n",
      " [ 0  0  0  0 30  0  0  1  0  0]\n",
      " [ 0  0  0  0  0 35  0  0  0  0]\n",
      " [ 1  0  0  0  0  0 31  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 38  1  0]\n",
      " [ 0  0  1  1  0  0  0  0 33  0]\n",
      " [ 0  0  0  1  0  1  0  0  0 26]]\n"
     ]
    }
   ],
   "source": [
    "y_test_class = np.argmax(y_test,axis=1)\n",
    "y_pred_class = np.argmax(y_pred,axis=1)\n",
    "\n",
    "print(classification_report(y_test_class,y_pred_class))\n",
    "print(confusion_matrix(y_test_class,y_pred_class))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
