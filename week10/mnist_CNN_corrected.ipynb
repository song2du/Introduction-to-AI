{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d592a57-e832-49c4-8559-82b674d7d36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torchsummary import summary\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "536c13c0-72b7-40ca-8f87-5f6c8ed2883b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x260e488ea50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#데이터 확인\n",
    "digits = datasets.load_digits()\n",
    "plt.imshow(digits.images[0], cmap=plt.cm.gray_r, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e91dce84-4bcd-4c22-bdbc-30ac58e8c8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1차 분할 후:\n",
      " (학습+검증) 세트: X_temp=(1437, 64), y_temp=(1437,)\n",
      " 테스트 세트: X_test_np=(360, 64), y_test_np=(360,)\n"
     ]
    }
   ],
   "source": [
    "# 2. 데이터 분할\n",
    "# 2-1. (학습+검증) 세트와 테스트 세트로 분할 (예: 80% / 20%)\n",
    "# stratify=y_full: 클래스 비율을 유지하면서 분할 (분류 문제에서 중요)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    digits.data, digits.target, test_size=0.2, random_state=42, stratify=digits.target\n",
    ")\n",
    "print(f\"\\n1차 분할 후:\")\n",
    "print(f\" (학습+검증) 세트: X_temp={X_temp.shape}, y_temp={y_temp.shape}\")\n",
    "print(f\" 테스트 세트: X_test_np={X_test.shape}, y_test_np={y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bff65b3d-5b65-4638-a37b-1f8eec309dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2차 분할 후:\n",
      " 학습 세트: X_train_np=(1077, 64), y_train_np=(1077,)\n",
      " 검증 세트: X_val_np=(360, 64), y_val_np=(360,)\n",
      " 테스트 세트: X_test_np=(360, 64), y_test_np=(360,)\n"
     ]
    }
   ],
   "source": [
    "# 2-2. (학습+검증) 세트를 다시 학습 세트와 검증 세트로 분할 (예: 75% / 25% -> 전체의 60% / 20%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp # 0.25 of 0.8 is 0.2 of total\n",
    ")\n",
    "print(f\"\\n2차 분할 후:\")\n",
    "print(f\" 학습 세트: X_train_np={X_train.shape}, y_train_np={y_train.shape}\")\n",
    "print(f\" 검증 세트: X_val_np={X_val.shape}, y_val_np={y_val.shape}\")\n",
    "print(f\" 테스트 세트: X_test_np={X_test.shape}, y_test_np={y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dfa8c216-eb3b-4bc1-a11d-d09efa141a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PyTorch 텐서로 변환 후 샘플 형태:\n",
      "X_train: torch.Size([1077, 64]), y_train: torch.Size([1077])\n",
      "X_val: torch.Size([360, 64]), y_val: torch.Size([360])\n",
      "X_test: torch.Size([360, 64]), y_test: torch.Size([360])\n"
     ]
    }
   ],
   "source": [
    "# 3. NumPy 배열을 PyTorch 텐서로 변환\n",
    "# 입력 데이터는 float 타입으로, 레이블은 long 타입(분류용)으로 변환합니다.\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val = torch.tensor(y_val, dtype=torch.long)\n",
    "\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "print(\"\\nPyTorch 텐서로 변환 후 샘플 형태:\")\n",
    "print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"X_val: {X_val.shape}, y_val: {y_val.shape}\")\n",
    "print(f\"X_test: {X_test.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1b473ef-81d2-4fb8-9300-e030698c2af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "데이터셋 크기:\n",
      "학습 데이터셋 크기: 1077\n",
      "검증 데이터셋 크기: 360\n",
      "테스트 데이터셋 크기: 360\n"
     ]
    }
   ],
   "source": [
    "# 4. TensorDataset 생성\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "print(f\"\\n데이터셋 크기:\")\n",
    "print(f\"학습 데이터셋 크기: {len(train_dataset)}\")\n",
    "print(f\"검증 데이터셋 크기: {len(val_dataset)}\")\n",
    "print(f\"테스트 데이터셋 크기: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63b0ec9f-e7b5-48eb-a53a-2034b20f2e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. DataLoader 생성\n",
    "batch_size = 64 # 배치 크기 설정\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False) # 검증 시에는 섞지 않음\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False) # 테스트 시에도 섞지 않음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c35a2a2-e86a-4b12-9962-76d1791fb496",
   "metadata": {},
   "source": [
    "## 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "894419b8-c49c-421d-858d-5a0cdea60e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MnistCNN, self).__init__()\n",
    "        # 입력 채널 수: 1 (흑백 이미지), 출력 채널 수: 16, 커널 크기: 3x3, 패딩: 1\n",
    "        # (N, 1, 8, 8) -> Conv1 -> (N, 16, 8, 8) -> ReLU -> (N, 16, 8, 8)\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        # MaxPool1 -> (N, 16, 4, 4)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # 입력 채널 수: 16, 출력 채널 수: 32, 커널 크기: 3x3, 패딩: 1\n",
    "        # (N, 16, 4, 4) -> Conv2 -> (N, 32, 4, 4) -> ReLU -> (N, 32, 4, 4)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        # MaxPool2 -> (N, 32, 2, 2)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # 컨볼루션 및 풀링 레이어 후의 특징 맵 크기 계산: 32 채널 * 2 높이 * 2 너비 = 128\n",
    "        # 이 값을 fc1의 입력 크기로 사용\n",
    "        self.fc1_input_features = 32 * 2 * 2\n",
    "        self.fc1 = nn.Linear(self.fc1_input_features, 128) # Fully Connected Layer 1\n",
    "        self.fc2 = nn.Linear(128, 10) # Output Layer (10 classes for digits 0-9)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = x.view(batch_size, 1, 8, 8) # 또는 x.reshape(batch_size, 1, 8, 8)\n",
    "        # 이제 x의 형태는 (batch_size, 1, 8, 8)\n",
    "        x = self.pool1(F.relu(self.conv1(x))) # (batch_size, 16, 4, 4)\n",
    "        x = self.pool2(F.relu(self.conv2(x))) # (batch_size, 32, 2, 2)\n",
    "        # Fully connected layer에 입력하기 위해 다시 평탄화\n",
    "        x = x.view(batch_size, -1) # (batch_size, 32 * 2 * 2)\n",
    "        # 또는 torch.flatten(x, start_dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x) # 분류 문제의 경우 마지막 레이어에 softmax는 보통 loss 함수(CrossEntropyLoss)에 포함됨\n",
    "        return x\n",
    "\n",
    "# Initialize the CNN model\n",
    "model = MnistCNN() # 모델 인스턴스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c9647a7c-167a-4939-9bae-01f247029cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1             [-1, 16, 8, 8]             160\n",
      "         MaxPool2d-2             [-1, 16, 4, 4]               0\n",
      "            Conv2d-3             [-1, 32, 4, 4]           4,640\n",
      "         MaxPool2d-4             [-1, 32, 2, 2]               0\n",
      "            Linear-5                  [-1, 128]          16,512\n",
      "            Linear-6                   [-1, 10]           1,290\n",
      "================================================================\n",
      "Total params: 22,602\n",
      "Trainable params: 22,602\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.02\n",
      "Params size (MB): 0.09\n",
      "Estimated Total Size (MB): 0.10\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, input_size=(1, 8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "07eb4da9-5fe7-43c9-b553-43c173c73475",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9300f5c-f2ad-4d7c-b488-67ca54a1f04e",
   "metadata": {},
   "source": [
    "## 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "92b95b5b-0d2a-4aa3-950b-bdea2c0ace3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Loss: 1.9964, Accuracy: 62.50%\n",
      "Epoch 2/30, Loss: 1.1170, Accuracy: 86.67%\n",
      "Epoch 3/30, Loss: 0.4887, Accuracy: 92.50%\n",
      "Epoch 4/30, Loss: 0.2849, Accuracy: 93.06%\n",
      "Epoch 5/30, Loss: 0.2082, Accuracy: 95.28%\n",
      "Epoch 6/30, Loss: 0.1437, Accuracy: 96.11%\n",
      "Epoch 7/30, Loss: 0.1056, Accuracy: 95.83%\n",
      "Epoch 8/30, Loss: 0.0896, Accuracy: 96.39%\n",
      "Epoch 9/30, Loss: 0.0715, Accuracy: 96.67%\n",
      "Epoch 10/30, Loss: 0.0661, Accuracy: 97.50%\n",
      "Epoch 11/30, Loss: 0.0528, Accuracy: 97.78%\n",
      "Epoch 12/30, Loss: 0.0468, Accuracy: 98.33%\n",
      "Epoch 13/30, Loss: 0.0432, Accuracy: 98.06%\n",
      "Epoch 14/30, Loss: 0.0310, Accuracy: 98.61%\n",
      "Epoch 15/30, Loss: 0.0309, Accuracy: 97.50%\n",
      "Epoch 16/30, Loss: 0.0347, Accuracy: 97.50%\n",
      "Epoch 17/30, Loss: 0.0279, Accuracy: 98.06%\n",
      "Epoch 18/30, Loss: 0.0210, Accuracy: 98.89%\n",
      "Epoch 19/30, Loss: 0.0202, Accuracy: 98.33%\n",
      "Epoch 20/30, Loss: 0.0183, Accuracy: 97.78%\n",
      "Epoch 21/30, Loss: 0.0155, Accuracy: 97.50%\n",
      "Epoch 22/30, Loss: 0.0109, Accuracy: 98.33%\n",
      "Epoch 23/30, Loss: 0.0106, Accuracy: 98.33%\n",
      "Epoch 24/30, Loss: 0.0078, Accuracy: 99.17%\n",
      "Epoch 25/30, Loss: 0.0085, Accuracy: 98.61%\n",
      "Epoch 26/30, Loss: 0.0069, Accuracy: 98.89%\n",
      "Epoch 27/30, Loss: 0.0060, Accuracy: 98.89%\n",
      "Epoch 28/30, Loss: 0.0057, Accuracy: 98.33%\n",
      "Epoch 29/30, Loss: 0.0047, Accuracy: 98.61%\n",
      "Epoch 30/30, Loss: 0.0038, Accuracy: 98.89%\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "# Variables to store loss and accuracy\n",
    "train_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 30\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_dataloader:\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        labels = labels.long()\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Calculate average loss over an epoch\n",
    "    train_losses.append(running_loss / len(train_dataloader))\n",
    "\n",
    "    # Evaluate on test data\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    threshold = 0.5  # 예측 임계값 설정\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_dataloader: #test 대신 validation\n",
    "            outputs = model(inputs)\n",
    "            _, predicted_indices = torch.max(outputs, 1) # 가장 높은 값을 가진 인덱스를 예측값으로 사용\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted_indices == labels).sum().item() # 레이블과 직접 비교\n",
    "\n",
    "    accuracy = correct / total * 100\n",
    "    test_accuracies.append(accuracy)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {train_losses[-1]:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cabe93-d73f-4d36-a19f-4df8bbc7edcb",
   "metadata": {},
   "source": [
    "## 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0d4b39f7-18dd-4979-970c-fbe6ec2dfdb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[35  0  0  0  1  0  0  0  0  0]\n",
      " [ 0 36  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 35  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 37  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 36  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 37  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 35  0  1  0]\n",
      " [ 0  0  0  0  0  0  0 36  0  0]\n",
      " [ 0  2  0  0  0  0  0  1 32  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 36]]\n",
      "F1 Score: 0.99\n",
      "Precision: 0.99\n",
      "Recall: 0.99\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dataloader: \n",
    "        outputs = model(inputs) # outputs shape: [batch_size, 10]\n",
    "\n",
    "        # 멀티클래스 분류: 가장 높은 점수(logit)를 가진 클래스의 인덱스를 예측값으로 사용\n",
    "        _, predicted_indices = torch.max(outputs, 1) # predicted_indices shape: [batch_size]\n",
    "\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_predictions.extend(predicted_indices.cpu().numpy()) # 1D 예측값 저장\n",
    "\n",
    "# Convert to numpy arrays\n",
    "all_labels = np.array(all_labels)\n",
    "all_predictions = np.array(all_predictions) # 이제 all_predictions도 1D 형태\n",
    "\n",
    "# Calculate metrics\n",
    "conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
    "\n",
    "# 멀티클래스인 경우 'average' 파라미터 조정 필요\n",
    "f1 = f1_score(all_labels, all_predictions, average='weighted') # 또는 'macro'\n",
    "precision = precision_score(all_labels, all_predictions, average='weighted') # 또는 'macro'\n",
    "recall = recall_score(all_labels, all_predictions, average='weighted') # 또는 'macro'\n",
    "# zero_division=0 또는 1을 precision_score, recall_score, f1_score에 추가하여 경고 방지 가능\n",
    "\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "print(f'F1 Score: {f1:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
