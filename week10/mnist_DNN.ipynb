{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a16fcf9-45c8-4972-95fb-98d5deb0c995",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torchsummary import summary\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "261b49fa-4b7b-4521-9da1-77b7803aa0e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1b3c6eb3680>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#데이터 확인\n",
    "digits = datasets.load_digits()\n",
    "plt.imshow(digits.images[0], cmap=plt.cm.gray_r, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb633df0-bab7-43cf-afe0-db4d7897ddc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#데이터 평탄화\n",
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "276902ec-2ff9-411b-82cb-1de6be5dd782",
   "metadata": {},
   "outputs": [],
   "source": [
    "#훈련, 테스트 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, digits.target, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "824f1a53-04e6-4319-9c95-58cd4a9d25cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\송이두\\AppData\\Local\\Temp\\ipykernel_27972\\3742484122.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train = torch.tensor(X_train, dtype=torch.float32)\n",
      "C:\\Users\\송이두\\AppData\\Local\\Temp\\ipykernel_27972\\3742484122.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_train = torch.tensor(y_train, dtype=torch.long)\n",
      "C:\\Users\\송이두\\AppData\\Local\\Temp\\ipykernel_27972\\3742484122.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test = torch.tensor(X_test, dtype=torch.float32)\n",
      "C:\\Users\\송이두\\AppData\\Local\\Temp\\ipykernel_27972\\3742484122.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test = torch.tensor(y_test, dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "#pytorch 텐서로 변환\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b1396af-c743-4c17-ac39-c7ce6b88a30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#텐서 데이터셋 설정 및 데이터 로더 설정\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c19ac3c-d7d6-464f-8836-d85bd9e5232d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1437, 64]),\n",
       " torch.Size([360, 64]),\n",
       " torch.Size([1437]),\n",
       " torch.Size([360]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bebb4c-bcf5-45d9-b04f-59f4ca1d90ab",
   "metadata": {},
   "source": [
    "## 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ac9aadb-47cd-4f60-85b6-cd16362b765b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistClf(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MnistClf, self).__init__()\n",
    "        self.fc1 = nn.Linear(64, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = MnistClf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e74e1966-bc57-4b59-ae11-386125657dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                  [-1, 128]           8,320\n",
      "            Linear-2                  [-1, 128]          16,512\n",
      "            Linear-3                   [-1, 64]           8,256\n",
      "            Linear-4                   [-1, 10]             650\n",
      "================================================================\n",
      "Total params: 33,738\n",
      "Trainable params: 33,738\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.13\n",
      "Estimated Total Size (MB): 0.13\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, input_size=(64,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24f32710-0142-435b-a1dc-8ab483bab5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa35041-9fe4-43f7-a0c0-561b90a17450",
   "metadata": {},
   "source": [
    "## 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3462a11d-0139-4278-a1a6-ef2a7ef57ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Loss: 0.0005, Accuracy: 96.67%\n",
      "Epoch 2/30, Loss: 0.0004, Accuracy: 96.94%\n",
      "Epoch 3/30, Loss: 0.0004, Accuracy: 96.94%\n",
      "Epoch 4/30, Loss: 0.0004, Accuracy: 96.94%\n",
      "Epoch 5/30, Loss: 0.0004, Accuracy: 96.94%\n",
      "Epoch 6/30, Loss: 0.0003, Accuracy: 96.94%\n",
      "Epoch 7/30, Loss: 0.0003, Accuracy: 96.94%\n",
      "Epoch 8/30, Loss: 0.0003, Accuracy: 96.67%\n",
      "Epoch 9/30, Loss: 0.0003, Accuracy: 96.94%\n",
      "Epoch 10/30, Loss: 0.0003, Accuracy: 96.94%\n",
      "Epoch 11/30, Loss: 0.0003, Accuracy: 96.67%\n",
      "Epoch 12/30, Loss: 0.0002, Accuracy: 96.94%\n",
      "Epoch 13/30, Loss: 0.0002, Accuracy: 96.67%\n",
      "Epoch 14/30, Loss: 0.0002, Accuracy: 96.94%\n",
      "Epoch 15/30, Loss: 0.0002, Accuracy: 96.94%\n",
      "Epoch 16/30, Loss: 0.0002, Accuracy: 96.94%\n",
      "Epoch 17/30, Loss: 0.0002, Accuracy: 96.94%\n",
      "Epoch 18/30, Loss: 0.0002, Accuracy: 96.67%\n",
      "Epoch 19/30, Loss: 0.0002, Accuracy: 96.94%\n",
      "Epoch 20/30, Loss: 0.0002, Accuracy: 96.67%\n",
      "Epoch 21/30, Loss: 0.0001, Accuracy: 97.22%\n",
      "Epoch 22/30, Loss: 0.0001, Accuracy: 96.94%\n",
      "Epoch 23/30, Loss: 0.0001, Accuracy: 96.94%\n",
      "Epoch 24/30, Loss: 0.0001, Accuracy: 96.67%\n",
      "Epoch 25/30, Loss: 0.0001, Accuracy: 96.94%\n",
      "Epoch 26/30, Loss: 0.0001, Accuracy: 96.94%\n",
      "Epoch 27/30, Loss: 0.0001, Accuracy: 96.67%\n",
      "Epoch 28/30, Loss: 0.0001, Accuracy: 96.94%\n",
      "Epoch 29/30, Loss: 0.0001, Accuracy: 96.94%\n",
      "Epoch 30/30, Loss: 0.0001, Accuracy: 96.67%\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "# Variables to store loss and accuracy\n",
    "train_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 30\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_dataloader:\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        labels = labels.long()\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Calculate average loss over an epoch\n",
    "    train_losses.append(running_loss / len(train_dataloader))\n",
    "\n",
    "    # Evaluate on test data\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    threshold = 0.5  # 예측 임계값 설정\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_dataloader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted_indices = torch.max(outputs, 1) # 가장 높은 값을 가진 인덱스를 예측값으로 사용\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted_indices == labels).sum().item() # 레이블과 직접 비교\n",
    "\n",
    "    accuracy = correct / total * 100\n",
    "    test_accuracies.append(accuracy)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {train_losses[-1]:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140d2971-cb6c-4e8a-a98f-4a240be31dc2",
   "metadata": {},
   "source": [
    "## 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b69bda3-48ff-45f6-b3d5-bb4fbae5e4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[35  0  0  0  1  0  0  0  0  0]\n",
      " [ 0 32  0  0  0  0  0  0  1  0]\n",
      " [ 0  0 35  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 37  0  2  0  0  0  0]\n",
      " [ 0  0  0  0 31  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 44  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 27  0  1  0]\n",
      " [ 0  0  0  0  0  0  0 41  0  0]\n",
      " [ 0  2  0  0  0  1  0  0 42  0]\n",
      " [ 0  0  0  0  0  1  0  0  3 24]]\n",
      "F1 Score: 0.97\n",
      "Precision: 0.97\n",
      "Recall: 0.97\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dataloader:\n",
    "        outputs = model(inputs) # outputs shape: [batch_size, 10]\n",
    "\n",
    "        # 멀티클래스 분류: 가장 높은 점수(logit)를 가진 클래스의 인덱스를 예측값으로 사용\n",
    "        _, predicted_indices = torch.max(outputs, 1) # predicted_indices shape: [batch_size]\n",
    "\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_predictions.extend(predicted_indices.cpu().numpy()) # 1D 예측값 저장\n",
    "\n",
    "# Convert to numpy arrays\n",
    "all_labels = np.array(all_labels)\n",
    "all_predictions = np.array(all_predictions) # 이제 all_predictions도 1D 형태\n",
    "\n",
    "# Calculate metrics\n",
    "conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
    "\n",
    "# 멀티클래스인 경우 'average' 파라미터 조정 필요\n",
    "f1 = f1_score(all_labels, all_predictions, average='weighted') # 또는 'macro'\n",
    "precision = precision_score(all_labels, all_predictions, average='weighted') # 또는 'macro'\n",
    "recall = recall_score(all_labels, all_predictions, average='weighted') # 또는 'macro'\n",
    "# zero_division=0 또는 1을 precision_score, recall_score, f1_score에 추가하여 경고 방지 가능\n",
    "\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "print(f'F1 Score: {f1:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
